<!-- Overview image -->
  <section class="hero">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <img src="static/images/fig1.png" alt="Overview of FineTuneBench" class="publication-image"/>
              <h2 class="subtitle has-text-centered">
                Overview of FineTuneBench evaluation framework and datasets
              </h2>
              <p class="has-text-justified is-size-6">
                <strong>Figure 1:</strong> A: Overview of FineTuneBench. We fine-tune five LLMs (GPT-4o, GPT-4o-mini, GPT-3.5-turbo, Gemini-1.5 Pro, Gemini-1.5 Flash) on four new datasets to test how well commercial fine-tuned APIs can learn and update knowledge. B: We provide an example from our Latest News dataset and the model responses before and after fine-tuning. The model is trained on each question and answer pair for up to 30 epochs, and then the model is re-evaluated on the same pair (Memorization). Then, we additionally evaluate the model on a modified version of the question that tests the model's ability to generalize its acquired knowledge beyond mere memorization (Generalization). In the Latest News dataset, we include two modifications: rephrasing, which involves changing the wording of the question but retaining the same answer; and date change, which keeps the original question but swaps out the year with a future date so that the correct response should be a refusal. We observe that although the fine-tuned model is able to memorize the original question, it fails at answering the rephrased question and the same question when the date is changed.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Results -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Results</h2>

          <!-- First result row -->
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <img src="static/images/fig2.png" alt="Performance on new knowledge tasks" class="publication-image"/>
                <h2 class="subtitle has-text-centered">
                  Performance of fine-tuned LLMs on new knowledge acquisition tasks
                </h2>
                <p class="has-text-justified is-size-6">
                  <strong>Figure 2:</strong> Performance of fine-tuned LLMs on the original training questions (Memorization) and modified questions (Generalization) for new knowledge acquisition datasets. A: On the Latest News dataset, we observe strong performance from the OpenAI models on the rephrased questions, especially from the gpt-4o-mini model. The Gemini models, on the other hand, struggle to even memorize the training data. This phenomenon is observed across all datasets. However, when the date is changed in the question, all models perform poorly, indicating that overfitting has occurred. B: On the Fictional People dataset, we observe a similar trend that the OpenAI models memorized well but performed worse on rephrased queries. Gemini was not able to learn this knowledge. When evaluating the models on the secondary (C) and comparison (D) questions, however, none of the models show significant improvement over the baseline models that have not been fine-tuned on the new knowledge.
                </p>
              </div>
            </div>
          </div>

          <!-- Second result row -->
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <img src="static/images/fig3.png" alt="Performance on updating knowledge tasks" class="publication-image"/>
                <h2 class="subtitle has-text-centered">
                  Performance of fine-tuned models on updating knowledge tasks
                </h2>
                <p class="has-text-justified is-size-6">
                  <strong>Figure 3:</strong> Performance of fine-tuned models on updating knowledge datasets. As compared to the new knowledge datasets, we observe lower performance in the rephrased questions from the Coding dataset. Of note, the ability of the models to memorize the Medical dataset questions drops, though its performance on the generalization task (Vignettes) is stronger comparatively.
                </p>
              </div>
            </div>
          </div>

        </div>
      </div>
    </div>
  </section>
